{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Done\n",
    "\n",
    "\n",
    "### ToDo\n",
    "\n",
    "\n",
    "# CartPole with Policy Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "Jupyter.keyboard_manager.command_shortcuts.add_shortcut('r', {\n",
       "    help : 'run all cells',\n",
       "    help_index : 'zz',\n",
       "\n",
       "    handler : function (event) {\n",
       "        IPython.notebook.execute_all_cells();\n",
       "        return false;\n",
       "    }\n",
       "});"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "\n",
    "Jupyter.keyboard_manager.command_shortcuts.add_shortcut('r', {\n",
    "    help : 'run all cells',\n",
    "    help_index : 'zz',\n",
    "\n",
    "    handler : function (event) {\n",
    "        IPython.notebook.execute_all_cells();\n",
    "        return false;\n",
    "    }\n",
    "});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "# Standard libraries\n",
    "\n",
    "# 3rd party libraries\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import gym\n",
    "\n",
    "# Custom libraries\n",
    "import CartPole_config as config\n",
    "import utils\n",
    "import networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Settings and parameters\n",
    "experiment_name = None\n",
    "experiment_name = 'CartPole_PG'\n",
    "\n",
    "batch_size = 5\n",
    "LEARNING_RATE = 1e-2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logdir:  ./logdir/CartPole-v1/A3C/CartPole_PG\n"
     ]
    }
   ],
   "source": [
    "## Derrived settings\n",
    "experiment_name = experiment_name or utils.time_str()\n",
    "logdir = './logdir/'+config.env_name+'/A3C/' + experiment_name\n",
    "print('logdir: ', logdir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from tensorflow.contrib.keras.api.keras.layers import Dense, Input\n",
    "from tensorflow.contrib.keras.api.keras.models import Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Create model\n",
    "tf.reset_default_graph()\n",
    "\n",
    "class PolicyGradient:\n",
    "    \n",
    "    def __init__(self, render=False):\n",
    "        self.env = gym.make(config.env_name)\n",
    "        self.render = render\n",
    "        self.should_stop = False\n",
    "        \n",
    "        self.obsPH = tf.placeholder(tf.float32, shape=[None]+[config.num_state], name='obsPlaceholder')\n",
    "        self.actionPH = tf.placeholder(tf.int32, shape=[None, 1], name='actionPlaceholder')\n",
    "        self.advantagePH = tf.placeholder(tf.float32, shape=[None, 1], \n",
    "                            name='advantagePlaceholder')\n",
    "\n",
    "        self.model = self._build_model()\n",
    "        self.graph = self._build_graph(LEARNING_RATE)\n",
    "\n",
    "        self.saver = tf.train.Saver(max_to_keep=5)\n",
    "        \n",
    "    def load_model(self, path):\n",
    "        ckpt = tf.train.get_checkpoint_state(path)\n",
    "        self.saver.restore(self.sess, ckpt.model_checkpoint_path)\n",
    "    \n",
    "    def save_model(self, path):\n",
    "        self.saver.save(self.sess, path)\n",
    "\n",
    "    def _build_model(self):\n",
    "        input_layer = Input(tensor=self.obsPH)\n",
    "        model_layers = networks.build_dense(input_layer, config.layers, name_stem='dense_')\n",
    "        model = Model(inputs=input_layer, outputs=model_layers)\n",
    "        return model\n",
    "\n",
    "    def _build_graph(self, learning_rate):\n",
    "        class PGGraph: pass\n",
    "        graph = PGGraph\n",
    "        \n",
    "        with tf.variable_scope('actor'):\n",
    "            action_hot = tf.one_hot(self.actionPH, config.num_action)\n",
    "            graph.action_probs = Dense(config.num_action, \n",
    "                                   activation='softmax')(self.model.output)\n",
    "            graph.action_prob = tf.reduce_sum(graph.action_probs * action_hot,\n",
    "                                    axis=1, keep_dims=True)\n",
    "            log_prob = tf.log(graph.action_prob)\n",
    "            graph.loss_total = - tf.reduce_mean(log_prob * self.advantagePH)\n",
    "            \n",
    "            optimizer = tf.train.RMSPropOptimizer(learning_rate=learning_rate)\n",
    "            \n",
    "            gradients, variables = optimizer.compute_gradients(graph.loss_total)\n",
    "            \n",
    "            # Summary of gradients and variables!\n",
    "            \n",
    "            clipped_gradients = [(tf.clip_by_value(grad, -1., 1.), var\n",
    "                                 for grad, var in zip(gradients, variables))]\n",
    "            \n",
    "            graph.train_op = optimizer.apply_gradients(clipped_gradients)\n",
    "            \n",
    "            \n",
    "    def stop(self):\n",
    "        self.should_stop = True\n",
    "\n",
    "    def get_action(self, obs):\n",
    "        \"\"\" Takes a single obs, and returns a single action\"\"\"\n",
    "        obs = [obs]\n",
    "        [p] = self.sess.run(\n",
    "                self.graph.action_probs,\n",
    "                feed_dict={self.brain.obsPH : obs})\n",
    "        a = np.random.choice(config.num_action, p=p)\n",
    "        return a\n",
    "    \n",
    "    def run(self):\n",
    "        self.sess = tf.Session()\n",
    "        obs_prev = self.env.reset()\n",
    "        try:\n",
    "            while self.should_stop is False:\n",
    "                action = get_action(obs_prev)\n",
    "                obs_new, reward, done, _ = self.env.step(action)\n",
    "                if self.render: self.env.render()\n",
    "                \n",
    "                # add experience to memory\n",
    "                \n",
    "                obs_prev = obs_new\n",
    "                    \n",
    "                if done:\n",
    "                    \n",
    "                    # stack experience\n",
    "                    \n",
    "                    # compute discounted rewards\n",
    "                    \n",
    "                    # normalize discounted rewards\n",
    "                \n",
    "                \n",
    "        except KeyboardInterrupt:\n",
    "            print('KeyboardInterrupt')\n",
    "\n",
    "agent = PolicyGradient()\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
