{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Done\n",
    "* Forward pass\n",
    "* Backwards pass\n",
    "* Summaries\n",
    "* Replay buffer\n",
    "* target network\n",
    "* Save model\n",
    "* Breakout \n",
    "* preprocessing\n",
    "* Action repeats\n",
    "* Set max episode length! (double of the mean?)\n",
    "* Encapsulate training in a class (or something!)\n",
    "* **properly use cartpole_config.py**\n",
    "* TensorBoard Summaries\n",
    "    * Track episode lengths!\n",
    "* Learning rate annealing?\n",
    "\n",
    "\n",
    "### Todo\n",
    "* Track variable values!\n",
    "* Let it train + collect data for report!\n",
    "\n",
    "### Notes\n",
    "Inspired by: https://medium.com/@awjuliani/simple-reinforcement-learning-with-tensorflow-part-4-deep-q-networks-and-beyond-8438a3e2b8df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DQN on Pong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "\n",
    "Jupyter.keyboard_manager.command_shortcuts.add_shortcut('r', {\n",
    "    help : 'run all cells',\n",
    "    help_index : 'zz',\n",
    "    handler : function (event) {\n",
    "        IPython.notebook.execute_all_cells();\n",
    "        return false;\n",
    "    }\n",
    "});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "## Standard libraries\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "## 3rd party\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import gym\n",
    "\n",
    "## Custom\n",
    "# import modelDQN\n",
    "import networks\n",
    "import utils\n",
    "import Pong_config as config\n",
    "import modelDQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Script behavior\n",
    "experiment_name = None\n",
    "experiment_name = 'conv'\n",
    "IS_DEBUGGING = True # Make progam run faster\n",
    "# IS_DEBUGGING = False\n",
    "\n",
    "## Training\n",
    "# learning_rate = 5e-4\n",
    "learning_rate = 0.00025 # Human paper\n",
    "# max_train_frame = 2e6\n",
    "max_train_frame = 2e6\n",
    "max_train_frame = 5e6\n",
    "max_episode_frame = 5000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IS_DEBUGGING:\n",
    "    config.eps_anneal_period = 1e5\n",
    "    config.replay_buffer_size = int(1e3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Derived settings\n",
    "prepro = utils.Preprocessor_2d(config.num_state, gray=True)\n",
    "env = utils.EnvironmentInterface(config, prepro, action_repeats=4, obs_buffer_size=4)\n",
    "\n",
    "for i in range(1):\n",
    "    print('i', i)\n",
    "#     run_name = experiment_name or utils.time_str()\n",
    "    run_name = experiment_name + utils.time_str()\n",
    "    logdir = './logdir/'+config.env_name+'/DQN/' + run_name\n",
    "    print('logdir\\t\\t', logdir)\n",
    "    if IS_DEBUGGING: logdir += '_debug'\n",
    "\n",
    "    ## Setup\n",
    "    tf.reset_default_graph()\n",
    "    random_seed = int(time.time())\n",
    "    tf.set_random_seed(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "    print('random seed\\t', random_seed)\n",
    "\n",
    "    print('Creating new model')\n",
    "    agent = modelDQN.DQN(config, env, logdir, learning_rate, max_train_frame=max_train_frame, max_episode_frame=max_episode_frame)\n",
    "    agent.build()\n",
    "    agent.run(load_model=False)\n",
    "\n",
    "#     agent.create_video('DQN', './tmp/CP_DQN_' + run_name + '.gif')\n",
    "    \n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env = gym.make('Pong-v0')\n",
    "env.reset()\n",
    "img = env.render(mode='rgb_array')\n",
    "print('img', type(img))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.create_video('DQN', './tmp/DQN.gif')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# agent.run(load_model=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
